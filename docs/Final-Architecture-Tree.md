# SmartCourse: Final Architecture Tree & Communication Flow

**Last Updated:** February 9, 2026

---

## Complete Project Structure

```
smart-course/
â”‚
â”œâ”€â”€ docker-compose.yml              # All infrastructure + services
â”œâ”€â”€ .env                            # Environment variables
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ infrastructure/                 # Shared configs
â”‚   â”œâ”€â”€ kafka/
â”‚   â”‚   â””â”€â”€ schema-registry/        # Event schemas
â”‚   â”œâ”€â”€ temporal/
â”‚   â”‚   â””â”€â”€ workflows/              # Shared workflow definitions
â”‚   â””â”€â”€ monitoring/
â”‚       â”œâ”€â”€ prometheus.yml
â”‚       â””â”€â”€ grafana/
â”‚           â””â”€â”€ dashboards/
â”‚
â”œâ”€â”€ services/                       # All microservices
â”‚   â”‚
â”‚   â”œâ”€â”€ api-gateway/               # Entry point (Port 8000)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_routes.py      # â†’ User Service
â”‚   â”‚   â”‚   â”œâ”€â”€ course_routes.py    # â†’ Course Service
â”‚   â”‚   â”‚   â”œâ”€â”€ enrollment_routes.py # â†’ Enrollment Service
â”‚   â”‚   â”‚   â””â”€â”€ progress_routes.py  # â†’ Progress Service
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”‚       â”œâ”€â”€ auth.py             # JWT verification
â”‚   â”‚       â””â”€â”€ rate_limit.py       # Rate limiting with Redis
â”‚   â”‚
â”‚   â”œâ”€â”€ user-service/              # User management (Port 8001)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ user.py             # SQLAlchemy model
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ user.py             # Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ auth.py             # POST /register, /login
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ user_service.py     # Business logic
â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL connection
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ jwt.py              # Token generation
â”‚   â”‚
â”‚   â”œâ”€â”€ course-service/            # Course management (Port 8002)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ course.py           # SQLAlchemy (PostgreSQL)
â”‚   â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”‚   â””â”€â”€ course_content.py   # Beanie (MongoDB)
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ course.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â”œâ”€â”€ courses.py          # GET/POST/PUT courses
â”‚   â”‚   â”‚   â””â”€â”€ publish.py          # POST /courses/{id}/publish
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ course_service.py
â”‚   â”‚   â”‚   â””â”€â”€ publish_service.py  # Triggers Temporal workflow
â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL + MongoDB
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py       # Publish events
â”‚   â”‚   â””â”€â”€ temporal_client.py      # Workflow client
â”‚   â”‚
â”‚   â”œâ”€â”€ enrollment-service/        # Enrollment logic (Port 8003)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ enrollment.py       # SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ enrollment.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ enrollments.py      # POST /enroll, GET /my-courses
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ enrollment_service.py # ACID transactions
â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL connection
â”‚   â”‚   â”œâ”€â”€ kafka_producer.py       # Publish enrollment.created
â”‚   â”‚   â””â”€â”€ temporal_client.py      # Start enrollment workflow
â”‚   â”‚
â”‚   â”œâ”€â”€ progress-service/          # Progress tracking (Port 8004)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ progress.py         # SQLAlchemy
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â””â”€â”€ progress.py
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ progress.py         # POST /lessons/{id}/complete
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ progress_service.py
â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL connection
â”‚   â”‚   â”œâ”€â”€ redis_client.py         # Cache progress data
â”‚   â”‚   â””â”€â”€ kafka_producer.py       # Publish progress.updated
â”‚   â”‚
â”‚   â”œâ”€â”€ notification-service/      # Notifications (Port 8005)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ consumers/
â”‚   â”‚   â”‚   â””â”€â”€ kafka_consumer.py   # Listen to events
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â””â”€â”€ celery_tasks.py     # Send emails, SMS
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ email_service.py
â”‚   â”‚   â”‚   â””â”€â”€ sms_service.py
â”‚   â”‚   â””â”€â”€ config.py
â”‚   â”‚
â”‚   â”œâ”€â”€ content-service/           # Content processing (Port 8006)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”‚   â””â”€â”€ content_chunk.py    # Beanie (MongoDB)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction_service.py # Extract text from videos/PDFs
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding_service.py  # Generate embeddings
â”‚   â”‚   â”‚   â””â”€â”€ vector_service.py     # Store in Qdrant
â”‚   â”‚   â”œâ”€â”€ database.py             # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ qdrant_client.py        # Vector DB client
â”‚   â”‚   â””â”€â”€ openai_client.py        # OpenAI API
â”‚   â”‚
â”‚   â”œâ”€â”€ ai-assistant-service/      # AI Q&A (Port 8007)
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ routers/
â”‚   â”‚   â”‚   â””â”€â”€ chat.py             # POST /ask
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py      # RAG pipeline
â”‚   â”‚   â”‚   â””â”€â”€ llm_service.py      # LLM integration
â”‚   â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”‚   â””â”€â”€ conversation.py     # Beanie (MongoDB)
â”‚   â”‚   â”œâ”€â”€ qdrant_client.py        # Retrieve similar chunks
â”‚   â”‚   â”œâ”€â”€ openai_client.py        # GPT-4 API
â”‚   â”‚   â””â”€â”€ database.py             # MongoDB
â”‚   â”‚
â”‚   â””â”€â”€ analytics-service/         # Analytics (Port 8008)
â”‚       â”œâ”€â”€ main.py
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â”œâ”€â”€ consumers/
â”‚       â”‚   â””â”€â”€ kafka_consumer.py   # All events
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â””â”€â”€ analytics.py        # SQLAlchemy
â”‚       â”œâ”€â”€ routers/
â”‚       â”‚   â””â”€â”€ reports.py          # GET /reports/enrollments
â”‚       â”œâ”€â”€ services/
â”‚       â”‚   â””â”€â”€ analytics_service.py
â”‚       â””â”€â”€ database.py             # PostgreSQL
â”‚
â”œâ”€â”€ workers/                        # Background processors
â”‚   â”‚
â”‚   â”œâ”€â”€ celery-workers/            # Task workers
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â”œâ”€â”€ worker.py               # Celery worker process
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â”œâ”€â”€ email_tasks.py      # send_welcome_email
â”‚   â”‚   â”‚   â”œâ”€â”€ sms_tasks.py
â”‚   â”‚   â”‚   â””â”€â”€ report_tasks.py
â”‚   â”‚   â””â”€â”€ config.py               # RabbitMQ connection
â”‚   â”‚
â”‚   â””â”€â”€ temporal-workers/          # Workflow workers
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â”œâ”€â”€ worker.py               # Temporal worker process
â”‚       â”œâ”€â”€ workflows/
â”‚       â”‚   â”œâ”€â”€ course_publish_workflow.py
â”‚       â”‚   â”œâ”€â”€ enrollment_workflow.py
â”‚       â”‚   â””â”€â”€ content_process_workflow.py
â”‚       â”œâ”€â”€ activities/
â”‚       â”‚   â”œâ”€â”€ course_activities.py
â”‚       â”‚   â”œâ”€â”€ enrollment_activities.py
â”‚       â”‚   â””â”€â”€ content_activities.py
â”‚       â””â”€â”€ config.py               # Temporal connection
â”‚
â”œâ”€â”€ shared/                         # Shared libraries
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ events.py               # Kafka event schemas
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ postgres.py             # Shared DB utils
â”‚   â”‚   â””â”€â”€ mongodb.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logging.py
â”‚       â””â”€â”€ metrics.py              # Prometheus metrics
â”‚
â””â”€â”€ migrations/                     # Database migrations
    â”œâ”€â”€ alembic.ini
    â”œâ”€â”€ env.py
    â””â”€â”€ versions/
        â”œâ”€â”€ 001_create_users_table.py
        â”œâ”€â”€ 002_create_courses_table.py
        â”œâ”€â”€ 003_create_enrollments_table.py
        â””â”€â”€ 004_create_progress_table.py
```

---

## Docker Compose Structure

```yaml
# docker-compose.yml

version: "3.8"

services:
  # ============ INFRASTRUCTURE LAYER ============

  postgres:
    image: postgres:15
    container_name: smartcourse-postgres
    environment:
      POSTGRES_DB: smartcourse
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data

  mongodb:
    image: mongo:7
    container_name: smartcourse-mongodb
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

  redis:
    image: redis:7-alpine
    container_name: smartcourse-redis
    ports:
      - "6379:6379"

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: smartcourse-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: smartcourse-kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092

  rabbitmq:
    image: rabbitmq:3-management
    container_name: smartcourse-rabbitmq
    ports:
      - "5672:5672" # AMQP
      - "15672:15672" # Management UI

  temporal:
    image: temporalio/auto-setup:latest
    container_name: smartcourse-temporal
    depends_on:
      - postgres
    ports:
      - "7233:7233" # gRPC
      - "8233:8233" # Web UI
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=postgres
      - POSTGRES_PWD=password
      - POSTGRES_SEEDS=postgres

  qdrant:
    image: qdrant/qdrant:latest
    container_name: smartcourse-qdrant
    ports:
      - "6333:6333"
    volumes:
      - qdrant_data:/qdrant/storage

  # ============ MICROSERVICES LAYER ============

  api-gateway:
    build: ./services/api-gateway
    container_name: smartcourse-api-gateway
    ports:
      - "8000:8000"
    environment:
      - USER_SERVICE_URL=http://user-service:8000
      - COURSE_SERVICE_URL=http://course-service:8000
      - ENROLLMENT_SERVICE_URL=http://enrollment-service:8000
      - PROGRESS_SERVICE_URL=http://progress-service:8000
      - REDIS_URL=redis://redis:6379
    depends_on:
      - redis

  user-service:
    build: ./services/user-service
    container_name: smartcourse-user-service
    ports:
      - "8001:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - REDIS_URL=redis://redis:6379
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - postgres
      - redis
      - kafka

  course-service:
    build: ./services/course-service
    container_name: smartcourse-course-service
    ports:
      - "8002:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - MONGODB_URL=mongodb://mongodb:27017
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - TEMPORAL_HOST=temporal:7233
    depends_on:
      - postgres
      - mongodb
      - kafka
      - temporal

  enrollment-service:
    build: ./services/enrollment-service
    container_name: smartcourse-enrollment-service
    ports:
      - "8003:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - TEMPORAL_HOST=temporal:7233
    depends_on:
      - postgres
      - kafka
      - temporal

  progress-service:
    build: ./services/progress-service
    container_name: smartcourse-progress-service
    ports:
      - "8004:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - REDIS_URL=redis://redis:6379
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - postgres
      - redis
      - kafka

  notification-service:
    build: ./services/notification-service
    container_name: smartcourse-notification-service
    ports:
      - "8005:8000"
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
    depends_on:
      - kafka
      - rabbitmq

  content-service:
    build: ./services/content-service
    container_name: smartcourse-content-service
    ports:
      - "8006:8000"
    environment:
      - MONGODB_URL=mongodb://mongodb:27017
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - mongodb
      - qdrant

  ai-assistant-service:
    build: ./services/ai-assistant-service
    container_name: smartcourse-ai-assistant-service
    ports:
      - "8007:8000"
    environment:
      - MONGODB_URL=mongodb://mongodb:27017
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - mongodb
      - qdrant

  analytics-service:
    build: ./services/analytics-service
    container_name: smartcourse-analytics-service
    ports:
      - "8008:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
    depends_on:
      - postgres
      - kafka

  # ============ WORKERS LAYER ============

  celery-worker:
    build: ./workers/celery-workers
    container_name: smartcourse-celery-worker
    command: celery -A worker worker --loglevel=info --concurrency=4
    environment:
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/
    depends_on:
      - rabbitmq
    deploy:
      replicas: 3 # 3 worker instances

  temporal-worker:
    build: ./workers/temporal-workers
    container_name: smartcourse-temporal-worker
    command: python worker.py
    environment:
      - TEMPORAL_HOST=temporal:7233
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/smartcourse
      - MONGODB_URL=mongodb://mongodb:27017
    depends_on:
      - temporal
      - postgres
      - mongodb
    deploy:
      replicas: 2 # 2 worker instances

  # ============ MONITORING ============

  prometheus:
    image: prom/prometheus:latest
    container_name: smartcourse-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana:latest
    container_name: smartcourse-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
    depends_on:
      - prometheus

volumes:
  postgres_data:
  mongodb_data:
  qdrant_data:
  prometheus_data:
  grafana_data:
```

---

## Service Communication Patterns

### **Pattern 1: Synchronous (REST)**

```
Client
  â”‚
  â””â”€â”€â†’ API Gateway (Port 8000)
         â”‚
         â”œâ”€â”€â†’ User Service (Port 8001)      [GET /users, POST /login]
         â”œâ”€â”€â†’ Course Service (Port 8002)    [GET /courses, POST /courses]
         â”œâ”€â”€â†’ Enrollment Service (Port 8003) [POST /enroll]
         â””â”€â”€â†’ Progress Service (Port 8004)  [POST /progress/complete]
```

**Example Flow:**

```
1. Client â†’ GET /api/courses
2. API Gateway â†’ Course Service: GET http://course-service:8000/courses
3. Course Service queries PostgreSQL
4. Course Service returns JSON
5. API Gateway returns to Client
```

---

### **Pattern 2: Asynchronous (Kafka Events)**

```
Enrollment Service
  â”‚
  â””â”€â”€â†’ Kafka Topic: "enrollment.created"
         â”‚
         â”œâ”€â”€â†’ Progress Service (Consumer)
         â”‚      â””â”€â”€â†’ Initialize progress in PostgreSQL
         â”‚
         â”œâ”€â”€â†’ Notification Service (Consumer)
         â”‚      â””â”€â”€â†’ Queue email task in RabbitMQ
         â”‚
         â””â”€â”€â†’ Analytics Service (Consumer)
                â””â”€â”€â†’ Update enrollment count in PostgreSQL
```

**Example Flow:**

```
1. Student enrolls via API
2. Enrollment Service creates record in PostgreSQL
3. Enrollment Service publishes to Kafka:
   {
     "event": "enrollment.created",
     "user_id": 123,
     "course_id": 456
   }
4. Progress Service receives event â†’ initializes progress
5. Notification Service receives event â†’ queues welcome email
6. Analytics Service receives event â†’ updates metrics
```

---

### **Pattern 3: Background Tasks (RabbitMQ + Celery)**

```
Notification Service
  â”‚
  â””â”€â”€â†’ RabbitMQ Queue: "email_queue"
         â”‚
         â””â”€â”€â†’ Celery Worker (3 instances)
                â”œâ”€â”€â†’ Worker 1: Sending email to user@example.com
                â”œâ”€â”€â†’ Worker 2: Sending SMS to +1234567890
                â””â”€â”€â†’ Worker 3: Idle (waiting for tasks)
```

**Example Flow:**

```
1. Notification Service receives Kafka event
2. Queue task: send_welcome_email.delay(user_id)
3. Task goes to RabbitMQ queue
4. Celery Worker picks up task
5. Worker sends email via SMTP/SendGrid
6. Worker marks task complete
```

---

### **Pattern 4: Workflows (Temporal)**

```
Course Service
  â”‚
  â””â”€â”€â†’ Temporal Server
         â”‚
         â””â”€â”€â†’ Temporal Worker (executes workflow)
                â”‚
                â”œâ”€â”€â†’ Activity 1: Validate course (PostgreSQL)
                â”œâ”€â”€â†’ Activity 2: Save content (MongoDB)
                â”œâ”€â”€â†’ Activity 3: Upload files (S3)
                â”œâ”€â”€â†’ Activity 4: Extract text (Content Service)
                â”œâ”€â”€â†’ Activity 5: Generate embeddings (OpenAI API)
                â”œâ”€â”€â†’ Activity 6: Store in Qdrant
                â””â”€â”€â†’ Activity 7: Mark published (PostgreSQL)
```

**Example Flow:**

```
1. Instructor clicks "Publish Course"
2. Course Service starts Temporal workflow
3. Temporal Worker executes activities sequentially
4. Each activity can retry on failure
5. Workflow survives server crashes
6. Frontend polls workflow status
```

---

## Complete Data Flow Examples

### **Flow 1: Student Enrolls in Course**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Client sends POST /api/courses/123/enroll                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. API Gateway forwards to Enrollment Service               â”‚
â”‚    POST http://enrollment-service:8000/enroll               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Enrollment Service (ACID Transaction)                    â”‚
â”‚    - Check if already enrolled (PostgreSQL)                 â”‚
â”‚    - Check course capacity (PostgreSQL)                     â”‚
â”‚    - Create enrollment record (PostgreSQL)                  â”‚
â”‚    - Publish event to Kafka: "enrollment.created"           â”‚
â”‚    - Start Temporal workflow: EnrollmentWorkflow            â”‚
â”‚    - Return enrollment_id to API Gateway                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Kafka broadcasts "enrollment.created" event              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                       â”‚                       â”‚
      â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Progress      â”‚    â”‚ Notification     â”‚    â”‚ Analytics    â”‚
â”‚ Service       â”‚    â”‚ Service          â”‚    â”‚ Service      â”‚
â”‚               â”‚    â”‚                  â”‚    â”‚              â”‚
â”‚ Initialize    â”‚    â”‚ Queue email task â”‚    â”‚ Update count â”‚
â”‚ progress in   â”‚    â”‚ in RabbitMQ      â”‚    â”‚ in PostgreSQLâ”‚
â”‚ PostgreSQL    â”‚    â”‚                  â”‚    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ RabbitMQ Queue   â”‚
                     â”‚ "email_queue"    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Celery Worker    â”‚
                     â”‚ Sends welcome    â”‚
                     â”‚ email to student â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Meanwhile (Parallel):**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Temporal Worker executes EnrollmentWorkflow              â”‚
â”‚                                                              â”‚
â”‚ Step 1: Call Progress Service API to initialize progress    â”‚
â”‚         (already done via Kafka, this is backup/verification)â”‚
â”‚                                                              â”‚
â”‚ Step 2: Call Notification Service to queue email            â”‚
â”‚         (already done via Kafka)                             â”‚
â”‚                                                              â”‚
â”‚ Step 3: Update user's enrolled courses cache in Redis       â”‚
â”‚                                                              â”‚
â”‚ Step 4: Mark workflow complete                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total Time:**

- API response: ~50ms (ACID transaction + Kafka publish)
- Email sent: ~2-5 seconds (background)
- Workflow complete: ~10 seconds

---

### **Flow 2: Instructor Publishes Course**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Instructor clicks "Publish Course"                       â”‚
â”‚    POST /api/courses/123/publish                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. API Gateway â†’ Course Service                             â”‚
â”‚    POST http://course-service:8000/courses/123/publish      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Course Service                                            â”‚
â”‚    - Update status to "publishing" (PostgreSQL)             â”‚
â”‚    - Start Temporal workflow: CoursePublishingWorkflow      â”‚
â”‚    - Return workflow_id to client                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Temporal Worker executes CoursePublishingWorkflow        â”‚
â”‚                                                              â”‚
â”‚ Step 1: Validate course completeness (PostgreSQL)           â”‚
â”‚ Step 2: Save content to MongoDB                             â”‚
â”‚ Step 3: Upload files to S3/MinIO                            â”‚
â”‚ Step 4: Extract text from videos/PDFs                       â”‚
â”‚         â†’ Call Content Service API                          â”‚
â”‚ Step 5: Generate embeddings (OpenAI API)                    â”‚
â”‚         â†’ Call Content Service API                          â”‚
â”‚ Step 6: Store embeddings in Qdrant                          â”‚
â”‚         â†’ Call Content Service API                          â”‚
â”‚ Step 7: Update search index (if using Elasticsearch)        â”‚
â”‚ Step 8: Mark course as "published" (PostgreSQL)             â”‚
â”‚ Step 9: Publish "course.published" event to Kafka           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Kafka broadcasts "course.published" event                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ Analytics      â”‚
         â”‚ Service        â”‚
         â”‚ Update metrics â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Frontend polling:**

```
Every 2 seconds:
  GET /api/workflows/{workflow_id}/status

Response:
  {
    "status": "RUNNING",
    "current_step": "Step 5/8: Generating embeddings",
    "progress": 62
  }
```

**Total Time:** 5-15 minutes (depending on course size)

---

### **Flow 3: Student Asks AI Question**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Student types: "Explain Python decorators"               â”‚
â”‚    POST /api/ai/ask                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. API Gateway â†’ AI Assistant Service                       â”‚
â”‚    POST http://ai-assistant-service:8000/ask                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. AI Assistant Service (RAG Pipeline)                      â”‚
â”‚                                                              â”‚
â”‚ Step 1: Generate query embedding (OpenAI API)               â”‚
â”‚         "Explain Python decorators" â†’ [0.23, 0.45, ...]     â”‚
â”‚                                                              â”‚
â”‚ Step 2: Search Qdrant for similar chunks                    â”‚
â”‚         Query: embedding vector                             â”‚
â”‚         Result: Top 5 relevant text chunks from course      â”‚
â”‚                                                              â”‚
â”‚ Step 3: Build context from retrieved chunks                 â”‚
â”‚         Context: "Decorators in Python are... @decorator..." â”‚
â”‚                                                              â”‚
â”‚ Step 4: Send to OpenAI GPT-4 with context                   â”‚
â”‚         Prompt: "Answer based on: {context}                 â”‚
â”‚                  Question: {question}"                      â”‚
â”‚                                                              â”‚
â”‚ Step 5: Stream response back to client                      â”‚
â”‚         Server-Sent Events (SSE)                            â”‚
â”‚                                                              â”‚
â”‚ Step 6: Save conversation to MongoDB                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total Time:**

- First token: <800ms
- Full response: 2-4 seconds (streaming)

---

## Service Dependencies Matrix

| Service                  | PostgreSQL | MongoDB | Redis | Kafka | RabbitMQ | Temporal | Qdrant |
| ------------------------ | ---------- | ------- | ----- | ----- | -------- | -------- | ------ |
| **API Gateway**          | âŒ         | âŒ      | âœ…    | âŒ    | âŒ       | âŒ       | âŒ     |
| **User Service**         | âœ…         | âŒ      | âœ…    | âœ…    | âŒ       | âŒ       | âŒ     |
| **Course Service**       | âœ…         | âœ…      | âŒ    | âœ…    | âŒ       | âœ…       | âŒ     |
| **Enrollment Service**   | âœ…         | âŒ      | âŒ    | âœ…    | âŒ       | âœ…       | âŒ     |
| **Progress Service**     | âœ…         | âŒ      | âœ…    | âœ…    | âŒ       | âŒ       | âŒ     |
| **Notification Service** | âŒ         | âŒ      | âŒ    | âœ…    | âœ…       | âŒ       | âŒ     |
| **Content Service**      | âŒ         | âœ…      | âŒ    | âŒ    | âŒ       | âŒ       | âœ…     |
| **AI Assistant**         | âŒ         | âœ…      | âŒ    | âŒ    | âŒ       | âŒ       | âœ…     |
| **Analytics Service**    | âœ…         | âŒ      | âŒ    | âœ…    | âŒ       | âŒ       | âŒ     |

---

## Network Communication Map

```
                    Internet
                       â”‚
                       â–¼
                 [Port 8000]
                 API Gateway
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
    [Port 8001]   [Port 8002]   [Port 8003]
    User Service  Course Svc    Enroll Svc
         â”‚             â”‚             â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
    [Port 8004]   [Port 8005]   [Port 8006]
    Progress Svc  Notify Svc    Content Svc
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚             â”‚             â”‚
    [Port 8007]   [Port 8008]
    AI Assistant  Analytics Svc

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
                  SHARED INFRASTRUCTURE
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

[Port 5432]      [Port 27017]     [Port 6379]
PostgreSQL       MongoDB          Redis

[Port 9092]      [Port 5672]      [Port 7233]
Kafka            RabbitMQ         Temporal

[Port 6333]
Qdrant (Vector DB)
```

---

## Startup Order

```bash
# 1. Start infrastructure (wait for healthy)
docker-compose up -d postgres mongodb redis zookeeper kafka rabbitmq temporal qdrant

# 2. Run database migrations
docker-compose run --rm alembic upgrade head

# 3. Start microservices
docker-compose up -d user-service course-service enrollment-service progress-service

# 4. Start additional services
docker-compose up -d notification-service content-service ai-assistant-service analytics-service

# 5. Start workers
docker-compose up -d celery-worker temporal-worker

# 6. Start API Gateway (entry point)
docker-compose up -d api-gateway

# 7. Start monitoring
docker-compose up -d prometheus grafana
```

**Or simply:**

```bash
docker-compose up -d
# Wait 30 seconds for everything to start
```

---

## Key Takeaways

### **Infrastructure Layer** (Shared, managed separately)

- PostgreSQL, MongoDB, Redis
- Kafka, RabbitMQ, Temporal
- Qdrant, Prometheus, Grafana

### **Microservices Layer** (Your code)

- 8 independent FastAPI services
- Each service in own container
- Each connects to needed infrastructure

### **Workers Layer** (Background processors)

- Celery workers (RabbitMQ tasks)
- Temporal workers (workflows)

### **Communication Patterns**

- **Synchronous:** API Gateway â†’ Services (REST)
- **Asynchronous:** Services â†’ Kafka â†’ Services (events)
- **Background:** Services â†’ RabbitMQ â†’ Celery (tasks)
- **Workflows:** Services â†’ Temporal â†’ Workers (orchestration)

### **Scaling Strategy**

- Add more service instances (horizontal scaling)
- Add more workers (Celery, Temporal)
- Kafka partitions for load distribution
- Redis caching for performance

---

**This is your complete architecture tree and communication flow!** ğŸš€
